<!DOCTYPE html>
<html>
  <head>
  <!-- 相關依賴套件載入 -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>

  <!-- 本章節採用tfjs，因此載入TF.js backend -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

  <!-- 載入手勢辨識模型 -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
  </head>
  <body>
  <!-- 用於呈現分析結果canvas -->
  <canvas id='canvas1'></canvas>
  <input type="file" id="uploadBtn" accept="image/*">

    <script>
    // 宣告canvas 物件
    const canvas1 = document.getElementById('canvas1');
    // 宣告canvas 繪圖物件
    var ctx = canvas1.getContext('2d')

    // 建立事件監聽器，當使用者選擇檔案時觸發
    document.getElementById('uploadBtn').addEventListener('change', handleUpload, false);

    // 觸發函式
    async function handleUpload(e) {
      const file = e.target.files[0]; // 取得上傳的檔案
      const base64String = await convertToBase64(file); // 將檔案轉換成 Base64 編碼

      // 建立影像物件
      var myImage = new Image();
      myImage.src = base64String;
      myImage.addEventListener("load", loadImage, false);
    }

    // 將檔案轉換成 Base64 編碼
    function convertToBase64(file) {
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.readAsDataURL(file);
        reader.onload = () => resolve(reader.result);
        reader.onerror = error => reject(error);
      });
    }

    // 觸發函式
    async function loadImage() {
      //方法1.等待~~確保 TensorFlow.js 在進行其他操作之前已經初始化。
      //await tf.ready();
      //方法2.等待 TensorFlow.js 初始化，確保後端已經設置好並且準備就緒。
      await tf.setBackend('webgl');
      
      img_width = myImage.width;
      img_height = myImage.height;

      canvas1.width = img_width;
      canvas1.height = img_height;

      ctx.strokeStyle = "red";
      ctx.font = "20px Arial";
      ctx.drawImage(myImage, 0, 0, img_width, img_height);

      const detectorConfig = {modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING};
      const detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);

      const poses = await detector.estimatePoses(canvas1);

      keypoints = poses[0].keypoints
      for (var i = 0; i < keypoints.length; i++) {
          console.log(keypoints[i]);

          x = keypoints[i].x
          y = keypoints[i].y

          name = keypoints[i].name

          ctx.beginPath();
          ctx.arc(x, y, 20, 0, 2 * Math.PI);
          ctx.stroke();

          ctx.fillText(name, x+30, y);
      }
    }
    </script>
  </body>
</html>
